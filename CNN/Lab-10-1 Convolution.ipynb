{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convoultion 정의\n",
    "\n",
    "- image 위에서 stride 값 만큼 filter(kernel)을 이동시키면서 겹쳐지는 부분의 각 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stride and padding\n",
    "\n",
    "- stride : filter를 한번에 얼마나 이동 할 것인가\n",
    "- padding : zero-padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **class** :   \n",
    "> torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력의 형태\n",
    "\n",
    "- input type : torch.Tensor\n",
    "- input shape : (N x C x H x W) : (batch_size, channel, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보기\n",
    "\n",
    "$$\n",
    "\\text{Output size} = \\frac{\\text{input_size} - \\text{filter} + \\text{(2*padding)}}{\\text{stride}} + 1\n",
    "$$\n",
    "\n",
    "## Convolution의 output 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:43:17.631808Z",
     "start_time": "2020-02-22T05:43:17.623808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution : Conv2d(1, 1, kernel_size=(11, 11), stride=(4, 4))\n",
      "inputs shape: torch.Size([1, 1, 227, 227])\n",
      "outputs shape: torch.Size([1, 1, 55, 55])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "# 예제 1)\n",
    "'''\n",
    "input image size : 227 x 227\n",
    "filter size = 11x11\n",
    "stride = 4\n",
    "padding = 0\n",
    "output image size = ? \n",
    "'''\n",
    "# Convolution setting\n",
    "conv = nn.Conv2d(1, 1, 11, stride=4, padding=0)\n",
    "print(\"Convolution : {}\".format(conv))\n",
    "\n",
    "# input\n",
    "inputs = torch.Tensor(1, 1, 227, 227)\n",
    "print(\"inputs shape: {}\".format(inputs.shape))\n",
    "\n",
    "# output\n",
    "out = conv(inputs)\n",
    "print(\"outputs shape: {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:04:37.594135Z",
     "start_time": "2020-02-22T05:04:37.587657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution : Conv2d(1, 1, kernel_size=(7, 7), stride=(2, 2))\n",
      "inputs shape: torch.Size([1, 1, 64, 64])\n",
      "outputs shape: torch.Size([1, 1, 29, 29])\n"
     ]
    }
   ],
   "source": [
    "# 예제 2)\n",
    "'''\n",
    "input image size : 64 x 64\n",
    "filter size = 7x7\n",
    "stride = 2\n",
    "padding = 0\n",
    "output image size = ? \n",
    "'''\n",
    "# Convolution setting\n",
    "conv = nn.Conv2d(1, 1, 7, stride=2, padding=0)\n",
    "print(\"Convolution : {}\".format(conv))\n",
    "\n",
    "# input\n",
    "inputs = torch.Tensor(1, 1, 64, 64)\n",
    "print(\"inputs shape: {}\".format(inputs.shape))\n",
    "\n",
    "# output\n",
    "out = conv(inputs)\n",
    "print(\"outputs shape: {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:05:37.152482Z",
     "start_time": "2020-02-22T05:05:37.145981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution : Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "inputs shape: torch.Size([1, 1, 32, 32])\n",
      "outputs shape: torch.Size([1, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 예제 3)\n",
    "'''\n",
    "input image size : 32 x 32\n",
    "filter size = 5x5\n",
    "stride = 1\n",
    "padding = 2\n",
    "output image size = ? \n",
    "'''\n",
    "# Convolution setting\n",
    "conv = nn.Conv2d(1, 1, 5, stride=1, padding=2)\n",
    "print(\"Convolution : {}\".format(conv))\n",
    "\n",
    "# input\n",
    "inputs = torch.Tensor(1, 1, 32, 32)\n",
    "print(\"inputs shape: {}\".format(inputs.shape))\n",
    "\n",
    "# output\n",
    "out = conv(inputs)\n",
    "print(\"outputs shape: {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:06:08.370720Z",
     "start_time": "2020-02-22T05:06:08.365221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution : Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "inputs shape: torch.Size([1, 1, 32, 64])\n",
      "outputs shape: torch.Size([1, 1, 28, 60])\n"
     ]
    }
   ],
   "source": [
    "# 예제 4)\n",
    "'''\n",
    "input image size : 32 x 64\n",
    "filter size = 5x5\n",
    "stride = 1\n",
    "padding = 0\n",
    "output image size = ?\n",
    "'''\n",
    "# Convolution setting\n",
    "conv = nn.Conv2d(1, 1, 5, stride=1, padding=0)\n",
    "print(\"Convolution : {}\".format(conv))\n",
    "\n",
    "# input\n",
    "inputs = torch.Tensor(1, 1, 32, 64)\n",
    "print(\"inputs shape: {}\".format(inputs.shape))\n",
    "\n",
    "# output\n",
    "out = conv(inputs)\n",
    "print(\"outputs shape: {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:06:32.696764Z",
     "start_time": "2020-02-22T05:06:32.690261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution : Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "inputs shape: torch.Size([1, 1, 64, 32])\n",
      "outputs shape: torch.Size([1, 1, 64, 32])\n"
     ]
    }
   ],
   "source": [
    "# 예제 5)\n",
    "'''\n",
    "input image size : 64 x 32\n",
    "filter size = 3x3\n",
    "stride = 1\n",
    "padding = 1\n",
    "output image size = ? \n",
    "'''\n",
    "# Convolution setting\n",
    "conv = nn.Conv2d(1, 1, 3, stride=1, padding=1)\n",
    "print(\"Convolution : {}\".format(conv))\n",
    "\n",
    "# input\n",
    "inputs = torch.Tensor(1, 1, 64, 32)\n",
    "print(\"inputs shape: {}\".format(inputs.shape))\n",
    "\n",
    "# output\n",
    "out = conv(inputs)\n",
    "print(\"outputs shape: {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron과 Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron과 Convolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T05:13:19.318921Z",
     "start_time": "2020-02-22T05:13:19.313426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 24, 24])\n",
      "torch.Size([1, 5, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.Tensor(1,1,28,28)\n",
    "conv1 = nn.Conv2d(1,5,5)\n",
    "pool = nn.MaxPool2d(2)\n",
    "out = conv1(inputs)\n",
    "out2 = pool(out)\n",
    "print(out.size())\n",
    "print(out2.size())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
